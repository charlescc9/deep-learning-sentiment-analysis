{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Movie Review Sentiment Analysis with TensorFlow\n",
    "\n",
    "Binary sentiment classification on IMDB movie reviews with a CNN model in TensorFlow\n",
    "* [2014 paper by Kim](https://arxiv.org/pdf/1408.5882v2.pdf)\n",
    "* [WILDML blog post](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n",
    "* [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/)\n",
    "* [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tflearn.data_utils import VocabularyProcessor\n",
    "\n",
    "# Define dataset directories\n",
    "train_pos_dir = 'aclImdb/train/pos/'\n",
    "train_neg_dir = 'aclImdb/train/neg/'\n",
    "test_pos_dir = 'aclImdb/test/pos/'\n",
    "test_neg_dir = 'aclImdb/test/neg/'\n",
    "\n",
    "# Define dataset size\n",
    "data_set_size = 12500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train reviews:\n",
      "anime underrated still hardly dorky kids movie noted still come back years first saw one better movi\n",
      "\n",
      "25000 test reviews:\n",
      "sure version film saw entertaining know twins gillian chung charlene choi seeing movie think english\n",
      "\n",
      "50000 total reviews:\n",
      "anime underrated still hardly dorky kids movie noted still come back years first saw one better movi\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train_pos = []\n",
    "for file_name in os.listdir(train_pos_dir):\n",
    "    with open(train_pos_dir + file_name, 'r') as myfile:\n",
    "        train_pos.append(myfile.read())\n",
    "        \n",
    "train_neg = []\n",
    "for file_name in os.listdir(train_neg_dir):\n",
    "    with open(train_neg_dir + file_name, 'r') as myfile:\n",
    "        train_neg.append(myfile.read())\n",
    "\n",
    "test_pos = []\n",
    "for file_name in os.listdir(test_pos_dir):\n",
    "    with open(test_pos_dir + file_name, 'r') as myfile:\n",
    "        test_pos.append(myfile.read())\n",
    "        \n",
    "test_neg = []\n",
    "for file_name in os.listdir(test_neg_dir):\n",
    "    with open(test_neg_dir + file_name, 'r') as myfile:\n",
    "        test_neg.append(myfile.read())                 \n",
    "        \n",
    "# Cleanse data    \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def parse_html(data):\n",
    "    data = BeautifulSoup(data, 'lxml').get_text() # Remove markup\n",
    "    data = re.sub(\"[^a-zA-Z]\",\" \", data) # Remove all non-alphanumeric characters\n",
    "    data = ' '.join([x for x in data.lower().split() if not x in stop_words]) # Remove stopwords\n",
    "    return data    \n",
    "    \n",
    "for i in xrange(data_set_size):\n",
    "    train_pos[i] = parse_html(train_pos[i])\n",
    "    train_neg[i] = parse_html(train_neg[i])\n",
    "    test_pos[i] = parse_html(test_pos[i])\n",
    "    test_neg[i] = parse_html(test_neg[i])    \n",
    "    \n",
    "train_x = np.concatenate([train_pos, train_neg])\n",
    "train_y = np.concatenate([[[0, 1] for _ in xrange(data_set_size)], [[1, 0] for _ in xrange(data_set_size)]])\n",
    "test_x = np.concatenate([test_pos, test_neg])\n",
    "test_y = np.concatenate([[[0, 1] for _ in xrange(data_set_size)], [[1, 0] for _ in xrange(data_set_size)]])\n",
    "total_x = np.concatenate([train_pos, train_neg, test_pos, test_neg])\n",
    "    \n",
    "print '%i train reviews:' % len(train_x)\n",
    "print train_x[0][:100]\n",
    "print '\\n%i test reviews:' % len(test_x)\n",
    "print test_x[0][:100]\n",
    "print '\\n%i total reviews:' % len(total_x)\n",
    "print total_x[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAFkCAYAAACJu/k0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVCrDhiRJKtX/B+rV9e5z7XaEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ce193b690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph distribution of review lengths\n",
    "%matplotlib inline\n",
    "review_lengths = sorted([len(x.split()) for x in train_x] + [len(x.split()) for x in test_x])[:49900]\n",
    "plt.show(plt.bar(range(len(review_lengths)), review_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert reviews into padded word indexes\n",
    "num_words = 250 # Based on graph (want to capture most reviews without too much padding)\n",
    "vocab_processor = VocabularyProcessor(num_words).fit_transform(total_x)\n",
    "total_x_vector = np.array(list(vocab_processor))\n",
    "train_x_vector = total_x_vector[:25000]\n",
    "test_x_vector = total_x_vector[25000:]\n",
    "\n",
    "# Shuffle data\n",
    "shuffled_i = np.random.permutation(np.arange(data_set_size * 2))\n",
    "train_x_vector_shuffled = train_x_vector[shuffled_i]\n",
    "train_y_shuffled = train_y[shuffled_i]\n",
    "test_x_vector_shuffled = test_x_vector[shuffled_i]\n",
    "test_y_shuffled = test_y[shuffled_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0: loss = 165.88, train accuracy = 45.31%\n",
      "Train epoch 1: loss = 27.66, train accuracy = 65.62%\n",
      "Train epoch 2: loss = 7.41, train accuracy = 75.00%\n",
      "Train epoch 3: loss = 6.32, train accuracy = 73.44%\n",
      "Train epoch 4: loss = 4.36, train accuracy = 73.44%\n",
      "Train epoch 5: loss = 3.18, train accuracy = 84.38%\n",
      "Train epoch 6: loss = 3.01, train accuracy = 87.50%\n",
      "Train epoch 7: loss = 2.98, train accuracy = 89.06%\n",
      "Train epoch 8: loss = 2.71, train accuracy = 89.06%\n",
      "Train epoch 9: loss = 2.32, train accuracy = 90.62%\n",
      "Test set accuracy: 69.92%\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "num_steps = int(data_set_size * 2 / batch_size * epochs)\n",
    "reg_constant = 0.01\n",
    "num_classes = 2\n",
    "vocab_size = max([max(x) for x in total_x_vector]) + 1 # 101244\n",
    "embedding_size = 128 \n",
    "patch_size_1 = 3\n",
    "patch_size_2 = 4\n",
    "patch_size_3 = 5\n",
    "num_channels = 1\n",
    "conv_depth = 128\n",
    "conv_stride = [1, 1, 1, 1]\n",
    "pool_stride = [1, 1, 1, 1]\n",
    "padding = 'VALID'\n",
    "losses = []\n",
    "\n",
    "# Graph\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as session:\n",
    "        # Input data\n",
    "        data_x_tf = tf.placeholder(tf.int32, [batch_size, num_words])\n",
    "        data_y_tf = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "        dropout_tf = tf.placeholder(tf.float32)\n",
    "\n",
    "        # Embeddeding\n",
    "        embedding_space = tf.Variable(tf.random_uniform([vocab_size, embedding_size])) \n",
    "        data_x_embedded = tf.nn.embedding_lookup(embedding_space, data_x_tf) \n",
    "        data_x_embedded_expanded = tf.expand_dims(data_x_embedded, -1) \n",
    "\n",
    "        # Fist convolution\n",
    "        conv_1_weights = tf.Variable(tf.truncated_normal([patch_size_1, embedding_size, num_channels, conv_depth]))\n",
    "        conv_1_biases = tf.Variable(tf.constant(0.1, shape=(conv_depth,)))\n",
    "        conv_1 = tf.nn.conv2d(data_x_embedded_expanded, conv_1_weights, conv_stride, padding)\n",
    "        conv_1_relu = tf.nn.relu(tf.nn.bias_add(conv_1, conv_1_biases))\n",
    "        pool_1 = tf.nn.max_pool(conv_1_relu, [1, num_words - patch_size_1 + 1, 1, 1], pool_stride, padding)\n",
    "\n",
    "        # Second convolution\n",
    "        conv_2_weights = tf.Variable(tf.truncated_normal([patch_size_2, embedding_size, num_channels, conv_depth]))\n",
    "        conv_2_biases = tf.Variable(tf.constant(0.1, shape=(conv_depth,)))\n",
    "        conv_2 = tf.nn.conv2d(data_x_embedded_expanded, conv_2_weights, conv_stride, padding)\n",
    "        conv_2_relu = tf.nn.relu(tf.nn.bias_add(conv_2, conv_2_biases))\n",
    "        pool_2 = tf.nn.max_pool(conv_2_relu, [1, num_words - patch_size_2 + 1, 1, 1], pool_stride, padding)\n",
    "\n",
    "        # Third convolution\n",
    "        conv_3_weights = tf.Variable(tf.truncated_normal([patch_size_3, embedding_size, num_channels, conv_depth]))\n",
    "        conv_3_biases = tf.Variable(tf.constant(0.1, shape=(conv_depth,)))\n",
    "        conv_3 = tf.nn.conv2d(data_x_embedded_expanded, conv_3_weights, conv_stride, padding)\n",
    "        conv_3_relu = tf.nn.relu(tf.nn.bias_add(conv_3, conv_3_biases))\n",
    "        pool_3 = tf.nn.max_pool(conv_3_relu, [1, num_words - patch_size_3 + 1, 1, 1], pool_stride, padding)\n",
    "\n",
    "        # Reshape\n",
    "        pool = tf.concat(3, [pool_1, pool_2, pool_3])\n",
    "        pool_shape = pool.get_shape().as_list()\n",
    "        reshaped_pool = tf.reshape(pool, [pool_shape[0],  pool_shape[3]])            \n",
    "        reshaped_pool_dropout = tf.nn.dropout(reshaped_pool, dropout_tf)           \n",
    "\n",
    "        # Output layer weights and biases\n",
    "        output_weights = tf.Variable(tf.truncated_normal([conv_depth * 3, num_classes]))\n",
    "        output_biases = tf.Variable(tf.constant(0.1, shape=(num_classes,)))                         \n",
    "        output = tf.nn.bias_add(tf.matmul(reshaped_pool_dropout, output_weights), output_biases)\n",
    "\n",
    "        # Loss, optimizer, and predictions\n",
    "        regularization = reg_constant * tf.nn.l2_loss(output_weights)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, data_y_tf) + regularization)\n",
    "        loss_summary = tf.scalar_summary('loss', loss)\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "        preds = tf.nn.softmax(output)\n",
    "\n",
    "        # Write accuracy to summary\n",
    "        sim = tf.equal(tf.argmax(preds, 1), tf.argmax(data_y_tf, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(sim, tf.float32)) * 100\n",
    "        accuracy_summary = tf.scalar_summary('accuracy', accuracy)           \n",
    "        merged_train = tf.merge_summary([loss_summary, accuracy_summary])\n",
    "        summary_writer_train = tf.train.SummaryWriter('tensorboard/train', session.graph)\n",
    " \n",
    "        # Train model\n",
    "        tf.initialize_all_variables().run()\n",
    "        for i in xrange(num_steps):\n",
    "            batch_start = batch_size * i % (data_set_size * 2 - batch_size)\n",
    "            batch_end = batch_start + batch_size\n",
    "            batch_x = train_x_vector_shuffled[batch_start:batch_end,:]\n",
    "            batch_y = train_y_shuffled[batch_start:batch_end,:]            \n",
    "            feed_dict = {data_x_tf: batch_x, data_y_tf: batch_y, dropout_tf: 0.5}   \n",
    "            _, l, summary, accuracy_train = session.run([optimizer, loss, merged_train, accuracy], feed_dict) \n",
    "            summary_writer_train.add_summary(summary, i)            \n",
    "            if i % int(num_steps / epochs) == 0:\n",
    "                epoch_num = int(i / int(num_steps / epochs))\n",
    "                print('Train epoch %d: loss = %.2f, train accuracy = %.2f%%' % (epoch_num, l, accuracy_train))\n",
    "\n",
    "        # Test model\n",
    "        test_preds_total = []\n",
    "        for i in xrange(int(np.floor(data_set_size * 2 / batch_size))):\n",
    "            batch_start = batch_size * i\n",
    "            batch_end = batch_start + batch_size\n",
    "            batch_x = test_x_vector_shuffled[batch_start:batch_end,:]\n",
    "            batch_y = test_y_shuffled[batch_start:batch_end,:]\n",
    "            feed_dict = {data_x_tf: batch_x, data_y_tf: batch_y, dropout_tf: 1.0}  \n",
    "            test_preds_total += (session.run([accuracy], feed_dict))\n",
    "        print 'Test set accuracy: %.2f%%' % (sum(test_preds_total) / len(test_preds_total))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis\n",
    "\n",
    "Sentiment Aanlysis with a CNN TensorFlow model. Based on:\n",
    "* [This blog post by WILDML](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n",
    "* [This 2014 paper by Kim](https://arxiv.org/pdf/1408.5882v2.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tflearn.data_utils import VocabularyProcessor\n",
    "\n",
    "# Define directories\n",
    "train_pos_dir = 'aclImdb/train/pos/'\n",
    "train_neg_dir = 'aclImdb/train/neg/'\n",
    "test_pos_dir = 'aclImdb/test/pos/'\n",
    "test_neg_dir = 'aclImdb/test/neg/'\n",
    "\n",
    "# Define dataset sizes\n",
    "data_set_size = 12500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train reviews:\n",
      "anime underrated still hardly dorky kids movie noted still come back years first saw one better movi\n",
      "\n",
      "25000 test reviews:\n",
      "sure version film saw entertaining know twins gillian chung charlene choi seeing movie think english\n"
     ]
    }
   ],
   "source": [
    "# Read and process data\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "with open('aclImdb/imdb.vocab', 'r') as myfile:\n",
    "    vocab = [x for x in myfile.read().split('\\n') if not x in stop_words]\n",
    "\n",
    "def parse_html(data):\n",
    "    data = BeautifulSoup(data, 'lxml').get_text() # Remove markup\n",
    "    data = re.sub(\"[^a-zA-Z]\",\" \", data) # Remove all non-alphanumeric characters\n",
    "    data = ' '.join([x for x in data.lower().split() if not x in stop_words]) # Remove stopwords\n",
    "    return data\n",
    "\n",
    "train_pos = []\n",
    "for file_name in os.listdir(train_pos_dir):\n",
    "    with open(train_pos_dir + file_name, 'r') as myfile:\n",
    "        train_pos.append(myfile.read())\n",
    "        \n",
    "train_neg = []\n",
    "for file_name in os.listdir(train_neg_dir):\n",
    "    with open(train_neg_dir + file_name, 'r') as myfile:\n",
    "        train_neg.append(myfile.read())\n",
    "\n",
    "test_pos = []\n",
    "for file_name in os.listdir(test_pos_dir):\n",
    "    with open(test_pos_dir + file_name, 'r') as myfile:\n",
    "        test_pos.append(myfile.read())\n",
    "        \n",
    "test_neg = []\n",
    "for file_name in os.listdir(test_neg_dir):\n",
    "    with open(test_neg_dir + file_name, 'r') as myfile:\n",
    "        test_neg.append(myfile.read())                 \n",
    "    \n",
    "for i in xrange(data_set_size):\n",
    "    train_pos[i] = parse_html(train_pos[i])\n",
    "    train_neg[i] = parse_html(train_neg[i])\n",
    "    test_pos[i] = parse_html(test_pos[i])\n",
    "    test_neg[i] = parse_html(test_neg[i])    \n",
    "    \n",
    "train_x = np.concatenate([train_pos, train_neg])\n",
    "train_y = np.concatenate([[[0, 1] for _ in xrange(data_set_size)], [[1, 0] for _ in xrange(data_set_size)]])\n",
    "test_x = np.concatenate([test_pos, test_neg])\n",
    "test_y = np.concatenate([[[0, 1] for _ in xrange(data_set_size)], [[1, 0] for _ in xrange(data_set_size)]])\n",
    "    \n",
    "print '%i train reviews:' % len(train_x)\n",
    "print train_x[0][:100]\n",
    "print '\\n%i test reviews:' % len(test_x)\n",
    "print test_x[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 49900 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAFkCAYAAACJu/k0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVCrDhiRJKtX/B+rV9e5z7XaEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf2e3f7250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph distribution of review lengths\n",
    "review_lengths = sorted([len(x.split()) for x in train_x] + [len(x.split()) for x in test_x])[:49900]\n",
    "plt.bar(range(len(review_lengths)), review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert reviews into padded word indexes\n",
    "num_words = 250 # Based on graph (want to capture most reviews without too much padding)\n",
    "train_x_vector = np.array(list(VocabularyProcessor(num_words).fit_transform(train_x)))\n",
    "test_x_vector = np.array(list(VocabularyProcessor(num_words).fit_transform(test_x)))\n",
    "\n",
    "# Shuffle data\n",
    "shuffled_i = np.random.permutation(np.arange(data_set_size * 2))\n",
    "train_x_vector = train_x_vector[shuffled_i]\n",
    "train_y = train_y[shuffled_i]\n",
    "test_x_vector = test_x_vector[shuffled_i]\n",
    "test_y = test_y[shuffled_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 8192000 values, but the requested shape has 64000000\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool, Reshape/shape)]]\n\nCaused by op u'Reshape', defined at:\n  File \"/home/charlie/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/charlie/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-141-6ccfd14072fb>\", line 47, in <module>\n    train_output = model(train_x_embedded)\n  File \"<ipython-input-141-6ccfd14072fb>\", line 42, in model\n    reshape = tf.reshape(pool, (int(pool.get_shape()[1]), num_words * word_embedding_size * conv_depth))\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1977, in reshape\n    name=name)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 8192000 values, but the requested shape has 64000000\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool, Reshape/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-6ccfd14072fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtrain_x_tf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_tf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 8192000 values, but the requested shape has 64000000\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool, Reshape/shape)]]\n\nCaused by op u'Reshape', defined at:\n  File \"/home/charlie/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/charlie/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-141-6ccfd14072fb>\", line 47, in <module>\n    train_output = model(train_x_embedded)\n  File \"<ipython-input-141-6ccfd14072fb>\", line 42, in model\n    reshape = tf.reshape(pool, (int(pool.get_shape()[1]), num_words * word_embedding_size * conv_depth))\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1977, in reshape\n    name=name)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/charlie/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 8192000 values, but the requested shape has 64000000\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool, Reshape/shape)]]\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "num_steps = 1\n",
    "batch_size = 64\n",
    "num_classes = 2\n",
    "vocab_size = len(vocab) # 89380\n",
    "word_embedding_size = 128 \n",
    "patch_size = 5\n",
    "num_channels = 1\n",
    "conv_depth = 16\n",
    "full_nodes = 16\n",
    "conv_stride = [1, 1, 1, 1]\n",
    "pool_stride = [1, 2, 2, 1]\n",
    "padding = 'SAME'\n",
    "\n",
    "# Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input layer\n",
    "    train_x_tf = tf.placeholder(tf.int32, [None, num_words])\n",
    "    train_y_tf = tf.placeholder(tf.float32, [None, num_classes])\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding_space = tf.Variable(tf.random_uniform([vocab_size, word_embedding_size])) # 89380 x 128\n",
    "    train_x_embedded = tf.nn.embedding_lookup(embedding_space, train_x_tf) # None x 250 x 128\n",
    "    train_x_embedded = tf.expand_dims(train_x_embedded, -1) # None x 250 x 128 x 1\n",
    "\n",
    "    # Convolution layer 5 x 5 x 1 x 16\n",
    "    conv_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, conv_depth]))\n",
    "    conv_biases = tf.Variable(tf.constant(0.1, shape=(conv_depth,)))\n",
    "    \n",
    "    # Fully connected layer\n",
    "    full_weights = tf.Variable(tf.truncated_normal([num_words * word_embedding_size * conv_depth, full_nodes]))\n",
    "    full_biases = tf.Variable(tf.constant(0.1, shape=(full_nodes,)))\n",
    "    \n",
    "    # Output layer\n",
    "    output_weights = tf.Variable(tf.truncated_normal([full_nodes, num_classes]))\n",
    "    output_biases = tf.Variable(tf.constant(0.1, shape=(num_classes,)))\n",
    "    \n",
    "    def model(data):\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(data, conv_weights, conv_stride, padding) + conv_biases)\n",
    "        pool = tf.nn.max_pool(conv, pool_stride, pool_stride, padding)\n",
    "        reshape = tf.reshape(pool, (int(pool.get_shape()[1]), num_words * word_embedding_size * conv_depth))\n",
    "        full = tf.nn.relu(tf.matmul(reshape, full_weights) + full_biases)\n",
    "        output = tf.matmul(full, output_weights) + output_biases\n",
    "        return output\n",
    "    \n",
    "    train_output = model(train_x_embedded)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(train_output, train_y_tf))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    train_predictions = tf.nn.softmax(train_output)\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    \n",
    "    for i in xrange(num_steps):\n",
    "        batch_start = batch_size * i % (train_y.shape[0] - batch_size)\n",
    "        batch_end = batch_start + batch_size\n",
    "        batch_X = train_x_vector[batch_start:batch_end,:]\n",
    "        batch_y = train_y[batch_start:batch_end,:]\n",
    "        feed_dict = {train_x_tf: batch_X, train_y_tf: batch_y}\n",
    "        _, l, preds = session.run([optimizer, loss, train_predictions], feed_dict) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
